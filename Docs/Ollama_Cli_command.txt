ollama --version   -----> check version

ollama ls   ----> list installed models

ollama pull modelname -----> pull(download) a modelname

ollama run modelname  -------> run a model

ollama rm modelname  -------> to remove the model from local system

/bye  -----> to stop/exit the model 

/clear  -----> delete the history of current  session

ollama run modelname " give the prompt"------> model will give the answer and exit auto

Multiline input
For multiline input, you can wrap text with """

ollama run embeddinggemma "Hello world"------------> generate embeddinggemma


ollama signin -------> sign in to ollama

ollama signout  ------> sign out of ollama

ollama serve-------> start ollama 

/show ---------> show the availabel command 

Available Commands:
  /show info     -->    Show details for this model
  /show license    -->  Show model license
  /show modelfile  -->  Show Modelfile for this model
  /show parameters --->  Show parameters for this model
  /show system    ---->   Show system message
  /show template   ----.  Show prompt template


/set ------> modify the parameters of current session 

Available Commands:
  /set parameter ...     Set a parameter
  /set system <string>   Set system message
  /set history           Enable history
  /set nohistory         Disable history
  /set wordwrap          Enable wordwrap
  /set nowordwrap        Disable wordwrap
  /set format json       Enable JSON mode
  /set noformat          Disable formatting
  /set verbose           Show LLM stats
  /set quiet             Disable LLM stats
  /set think             Enable thinking
  /set nothink           Disable thinking



/set parameter
Available Parameters:
  /set parameter seed <int>             Random number seed
  /set parameter num_predict <int>      Max number of tokens to predict       
  /set parameter top_k <int>            Pick from top k num of tokens
  /set parameter top_p <float>          Pick token based on sum of probabilities
  /set parameter min_p <float>          Pick token based on top token probability * min_p
  /set parameter num_ctx <int>          Set the context size
  /set parameter temperature <float>    Set creativity level
  /set parameter repeat_penalty <float> How strongly to penalize repetitions  
  /set parameter repeat_last_n <int>    Set how far back to look for repetitions
  /set parameter num_gpu <int>          The number of layers to send to the GPU
  /set parameter stop <string> <string> ...   Set the stop parameters  